library(keras)
#install_keras()
library(tidyverse)
library(tidymodels)
library(magrittr)
#install.packages("varhandle")
library(varhandle)
set.seed(1)
dataTotal <- read_csv("./data/breast_cancer_reduced.csv")
dataTotal$id <- NULL
dataTotal
data <- dataTotal[sample(nrow(dataTotal), 200), ]
data_split <- data %>% initial_split(prop = 3/4)
train_data <- training(data_split)
test_data  <- testing(data_split)
Xtraining <- train_data %>% select(-c(diagnosis)) %>% as.matrix()
Xtest <- test_data %>% select(-c(diagnosis)) %>% as.matrix()
Ytraining <- train_data %>% pull(diagnosis) %>% to.dummy("diagnosis")
Ytest <- test_data %>% pull(diagnosis) %>% to.dummy("diagnosis")
smaller_model <-
keras_model_sequential() %>%
layer_dense(units = 2, activation = "relu", input_shape = 11) %>%
layer_dense(units = 2, activation = "sigmoid")
smaller_model %>% compile(
optimizer = "adam",
loss = "binary_crossentropy",
metrics = list("accuracy")
)
smaller_model %>% summary()
baseline_model <-
keras_model_sequential() %>%
layer_dense(units = 16, activation = "relu", input_shape = 11) %>%
layer_dense(units = 16, activation = "relu") %>%
layer_dense(units = 2, activation = "sigmoid")
baseline_model %>% compile(
optimizer = "adam",
loss = "binary_crossentropy",
metrics = list("accuracy")
)
baseline_model %>% summary()
bigger_model <-
keras_model_sequential() %>%
layer_dense(units = 512, activation = "relu", input_shape = 11) %>%
layer_dense(units = 512, activation = "relu") %>%
layer_dense(units = 2, activation = "sigmoid")
bigger_model %>% compile(
optimizer = "adam",
loss = 'binary_crossentropy',
metrics = list("accuracy")
)
bigger_model %>% summary()
historial_mediano <- modelo_mediano %>% fit(
Xtraining,
Ytraining,
my_epochs,
my_batch_size,
validation_data = list(Xtest, Ytest),
verbose = 2
)
smaller_history <- smaller_model %>% fit(
Xtraining,
Ytraining,
my_epochs,
my_batch_size,
validation_data = list(Xtest, Ytest),
verbose = 2
)
#hiperparámetros
my_epochs = 300
my_batch_size = 20
smaller_history <- smaller_model %>% fit(
Xtraining,
Ytraining,
my_epochs,
my_batch_size,
validation_data = list(Xtest, Ytest),
verbose = 2
)
# su código aquí
baseline_history <- baseline_model %>% fit(
Xtraining,
Ytraining,
my_epochs,
my_batch_size,
validation_data = list(Xtest, Ytest),
verbose = 2
)
# su código aquí
bigger_history <- bigger_model() %>% fit(
Xtraining,
Ytraining,
my_epochs,
my_batch_size,
validation_data = list(Xtest, Ytest),
verbose = 2
)
# su código aquí
bigger_history <- bigger_model %>% fit(
Xtraining,
Ytraining,
my_epochs,
my_batch_size,
validation_data = list(Xtest, Ytest),
verbose = 2
)
callback1 <- callback_early_stopping(monitor = 'val_loss',
min_delta = 0,
patience = 7,
verbose = 1,
restore_best_weights = TRUE)
callback2 <- callback_model_checkpoint("my_model",
monitor='val_loss',
mode='min',
save_best_only=TRUE,
verbose=1)
callback3 <- callback_tensorboard(log_dir = './logs')
smaller_history <- smaller_model %>% fit(
Xtraining,
Ytraining,
my_epochs,
my_batch_size,
callbacks = list(callback1, callback2, callback3),
validation_data = list(Xtest, Ytest),
verbose = 2
)
